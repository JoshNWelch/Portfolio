---
title: "Heart Disease"
author: "Joshua Welch"
date: "April 17, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Heart
Here we are pulling in the data and changing the column names as we as setting columns to factors.

```{r heart}
heart = read.table("https://raw.githubusercontent.com/grbruns/cst383/master/heart.dat", quote = "/")
names(heart) <- c("AGE", "SEX", "CHESTPAIN", "RESTBP", "CHOL",
                  "SUGAR", "ECG", "MAXHR", "ANGINA", "DEP", "EXERCISE", "FLUOR",
                  "THAL", "OUTPUT")
names(heart) = tolower(names(heart))

# convert output to 0-1 range
heart$output = heart$output - 1  

# categorical variables to factors
heart$sex = factor(heart$sex)
heart$sugar = factor(heart$sugar)
heart$angina = factor(heart$angina)
heart$chestpain = factor(heart$chestpain)
heart$ecg = factor(heart$ecg)
heart$thal = factor(heart$thal)
heart$exercise = factor(heart$exercise)

```

## Exploration
Looking at the data there is 270 rows of data with 14 columns. The data appears to have no missing or incomplete rows. 


```{r exploration, echo=TRUE}
summary(heart)
str(heart)
sum(is.na(heart))
```
```{r exploration hist, echo=TRUE}
hist(heart$maxhr, main="Max heart rate of test subjects", xlab="Max HR", col="blue")
```

```{r exploration scat, echo=TRUE}
plot(heart[,c("age","maxhr")])
```

##Building the Model 1
Model 1 is created simply using all of the columns, not the best idea but gives a good idea of the data to see which columns are more useful than others. Since the data set is rather small this is easy to run, where a larger data set could be problematic. 
```{r model, echo=TRUE}
nrows=nrow(heart)
tr_rows=sample(1:nrows, 0.7*nrows)
tr_dat=heart[tr_rows,]
te_dat=heart[-tr_rows,]
fit1 = glm(output ~ ., data=tr_dat, family=binomial)
summary(fit1)
```

  From the summary we can see which columns are more useful than others, all though this doesn't take into account combination of columns.
  
```{r asses, echo=TRUE}
y = predict(fit1, newdata=te_dat, type="response")
predicts = as.numeric(y > 0.6)
actuals = te_dat$output
conf_mtx = table(predicts, actuals)
conf_mtx
```

```{r accuracy, echo=TRUE}
succ_rate = mean(predicts == actuals)
round(succ_rate, 3)
```

```{r model1 plot1, echo=TRUE}
par(mfrow=c(1,2))
hist(y[actuals == 0], main="Output when no heart disease", 
breaks=10, xlim=c(0,1), ylim=c(0,15), col="blue", xlab="Model predictions")
hist(y[actuals == 1], main="Output when heart disease", 
breaks=10, xlim=c(0,1), ylim=c(0,15), col="blue", xlab="Model predictions")
```

```{r model1 plot2, echo=TRUE}
plot(density(y[actuals == 1]), col="red", main="")
lines(density(y[actuals == 0]), col="green")
abline(v=0.6, lty=3)
legend("topleft", c("Heart Disease","No Heart Disease"), col= c("red","green"), lty=1)
```

```{r Threshold, echo=TRUE}
prec_recall_summary = function(predicts, actuals){
thresh = seq(0, 1, length.out=50)
prec_rec = data.frame()
actuals = factor(as.numeric(actuals))
for (th in thresh){
predicts = factor(as.numeric(y >= th), levels=c("0","1"))
prec_rec = rbind(prec_rec, as.vector(table(predicts, actuals)))
}
names(prec_rec) = c("TN", "FP", "FN", "TP")
prec_rec$threshold = thresh
prec_rec$precision = prec_rec$TP/(prec_rec$TP + prec_rec$FP)
prec_rec$recall    = prec_rec$TP/(prec_rec$TP + prec_rec$FN)
prec_rec$false_pos = prec_rec$FP/(prec_rec$FP + prec_rec$TN)
return(prec_rec)
}
prec_rec1 = prec_recall_summary(predicts, actuals)

plot(precision~threshold,data=prec_rec1, type="l")
plot(recall~threshold, data=prec_rec1, type="l")
```

```{r ROC, echo=TRUE}
plot(recall~false_pos, data=prec_rec1, type="l")
```

##Building Model 2
Model 2 is a little more careful by only choosing more beneficial columns and not using columns that have little to no effect.

```{r model2, echo=TRUE}
fit2 = glm(output ~ fluor + maxhr + thal, data=tr_dat, family=binomial)
summary(fit2)
```

```{r asses2, echo=TRUE}
y = predict(fit2, newdata=te_dat, type="response")
predicts = as.numeric(y > 0.6)
actuals = te_dat$output
conf_mtx = table(predicts, actuals)
conf_mtx
```

```{r accuracy2, echo=TRUE}
succ_rate = mean(predicts == actuals)
round(succ_rate, 3)
```

```{r model2 plot1, echo=TRUE}
par(mfrow=c(1,2))
hist(y[actuals == 0], main="Output when no heart disease", 
breaks=10, xlim=c(0,1), ylim=c(0,15), col="blue", xlab="Model predictions")
hist(y[actuals == 1], main="Output when heart disease", 
breaks=10, xlim=c(0,1), ylim=c(0,15), col="blue", xlab="Model predictions")
```

```{r model2 plot2, echo=TRUE}
plot(density(y[actuals == 1]), col="red", main="")
lines(density(y[actuals == 0]), col="green")
abline(v=0.6, lty=3)
legend("topleft", c("Heart Disease","No Heart Disease"), col= c("red","green"), lty=1)
```

```{r Threshold2, echo=TRUE}
prec_rec2 = prec_recall_summary(predicts, actuals)

plot(precision~threshold,data=prec_rec2, type="l")
plot(recall~threshold, data=prec_rec2, type="l")
```
##Conclusion
Here we can see the differenct between the 2 different models. The models are very similar, but the second model could still be improved by adding another column or using a variation of combination of columns.
```{r ROC2, echo=TRUE}
plot(recall~false_pos, data=prec_rec2, type="l", col="blue")
lines(recall~false_pos, data=prec_rec1, type="l", col="green")
abline(v=0.6, lty=3)
legend("topleft", c("Model 1","Model 2"), col= c("green","blue"), lty=1)
```